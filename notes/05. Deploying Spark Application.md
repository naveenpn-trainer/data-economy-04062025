# Deploying Spark Application

Scenario 01

```
spark-submit \
--master yarn \
--name "User Data Analysis" \
user_data_analysis.py /users.dat /output_1101
```


Scenario 02

```
spark-submit \
--master yarn \
--name "User Data Analysis" \
--py-files spark_initializer.py,spark_functions.py \
user_data_analysis.py /users.dat /output_1102
```

Scenario 03

```
spark-submit \
--master yarn \
--name "User Data Analysis" \
--py-files example_03.zip \
user_data_analysis.py /users.dat /output_1102
```

**Scenario 04**

```
spark-submit \
--master yarn \
--name "User Data Analysis" \
--py-files example_03.zip \
--conf "spark.sql.shuffle.partitions=100"
user_data_analysis.py /users.dat /output_1102
```

